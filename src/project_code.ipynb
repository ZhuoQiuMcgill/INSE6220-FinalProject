{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSE6220 Final Project — KOI koi_score Surrogate Model\n",
    "\n",
    "This notebook follows the agreed framework: clean the raw KOI table, save a clean dataset for reuse, and provide a dedicated \"Load Cleaned Data\" block for all later steps (EDA, PCA, and modeling)."
   ],
   "id": "ff074385165bd88a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use this notebook\n",
    "1. Run the Setup cells below.\n",
    "2. Run the \"Data Cleaning (run once)\" cell to generate `data/koi_clean.csv`.\n",
    "3. For all later work, use the \"Load Cleaned Data\" cell only — do not re-run cleaning (to avoid leakage and ensure reproducibility)."
   ],
   "id": "cf8a4d94dafff97d"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "source": [
    "# Setup: imports and paths\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Resolve raw and clean paths robustly relative to working directory\n",
    "RAW_CANDIDATES = [\n",
    "    os.path.join('data', 'koi.csv'),\n",
    "    os.path.join('..', 'data', 'koi.csv'),\n",
    "]\n",
    "RAW_PATH = next((p for p in RAW_CANDIDATES if os.path.isfile(p)), RAW_CANDIDATES[0])\n",
    "DATA_DIR = os.path.dirname(RAW_PATH) if os.path.basename(RAW_PATH) else os.path.join('data')\n",
    "CLEAN_PATH = os.path.join(DATA_DIR, 'koi_clean.csv')"
   ],
   "id": "ff9b5accb56216f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "source": [
    "# Column groups (kept consistent with the framework)\n",
    "IDENTIFIER_COLS = [\n",
    "    'kepid',            # Kepler Catalog ID\n",
    "    'kepoi_name',       # KOI Name\n",
    "    'kepler_name',      # Official Kepler Planet Name (if any)\n",
    "]\n",
    "\n",
    "TARGET_COL = 'koi_score'\n",
    "\n",
    "LABEL_COLS = [\n",
    "    'koi_disposition',     # Exoplanet Archive Disposition\n",
    "    'koi_pdisposition',    # Disposition Using Kepler Data\n",
    "    'koi_fpflag_nt',       # Not Transit-Like FP flag\n",
    "    'koi_fpflag_ss',       # Stellar Eclipse FP flag\n",
    "    'koi_fpflag_co',       # Centroid Offset FP flag\n",
    "    'koi_fpflag_ec',       # Ephemeris Match FP flag\n",
    "]\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    # Transit geometry & shape\n",
    "    'koi_period',\n",
    "    'koi_time0bk',\n",
    "    'koi_impact',\n",
    "    'koi_duration',\n",
    "    'koi_depth',\n",
    "    'koi_model_snr',\n",
    "    # Planet properties & irradiation\n",
    "    'koi_prad',\n",
    "    'koi_teq',\n",
    "    'koi_insol',\n",
    "    # Stellar properties\n",
    "    'koi_steff',\n",
    "    'koi_slogg',\n",
    "    'koi_srad',\n",
    "    # Sky position & brightness\n",
    "    'ra',\n",
    "    'dec',\n",
    "    'koi_kepmag',\n",
    "]\n",
    "\n",
    "# Always drop from feature matrix (metadata), per framework\n",
    "DROP_ALWAYS = ['koi_tce_plnt_num', 'koi_tce_delivname']\n",
    "\n",
    "ALL_KEEP_COLS = IDENTIFIER_COLS + [TARGET_COL] + LABEL_COLS + FEATURE_COLS"
   ],
   "id": "521c2b40b7de146f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning (run once)\n",
    "Cleans the raw KOI table according to the framework and writes `data/koi_clean.csv`.\n",
    "\n",
    "Notes:\n",
    "- Skips comment lines from the raw NASA export.\n",
    "- Retains identifier columns, target `koi_score`, label/flag columns, and the primary feature columns (central values only).\n",
    "- Drops uncertainty columns (`*_err1`, `*_err2`) implicitly by not selecting them.\n",
    "- Drops exact duplicate rows.\n",
    "- Drops rows with missing or out-of-range `koi_score`.\n",
    "- Does not impute feature missing values here (to avoid leakage) — handle later within ML pipelines."
   ],
   "id": "85a40f76736a020e"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "cleaning"
    ]
   },
   "source": [
    "def clean_koi(raw_path: str, out_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load raw KOI CSV, select relevant columns, enforce basic validity of koi_score,\n",
    "    and save a clean CSV for downstream use.\n",
    "    \"\"\"\n",
    "    # Load raw CSV; ignore NASA header comments starting with '#'\n",
    "    df = pd.read_csv(raw_path, comment='#', low_memory=False)\n",
    "    orig_rows = len(df)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Keep only the specified columns if present\n",
    "    keep_cols = [c for c in ALL_KEEP_COLS if c in df.columns]\n",
    "    df = df.loc[:, keep_cols].copy()\n",
    "\n",
    "    # Drop exact duplicate rows\n",
    "    before_dupes = len(df)\n",
    "    df = df.drop_duplicates()\n",
    "    dropped_dupes = before_dupes - len(df)\n",
    "\n",
    "    # Coerce numeric columns\n",
    "    numeric_cols = set(FEATURE_COLS + [TARGET_COL, 'kepid'])\n",
    "    numeric_cols.update([c for c in LABEL_COLS if c.startswith('koi_fpflag_')])\n",
    "    numeric_cols = [c for c in numeric_cols if c in df.columns]\n",
    "    for c in numeric_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    # Remove rows with missing target\n",
    "    before_drop_y_na = len(df)\n",
    "    df = df.dropna(subset=[TARGET_COL])\n",
    "    dropped_y_na = before_drop_y_na - len(df)\n",
    "\n",
    "    # Enforce koi_score within [0, 1]\n",
    "    before_range = len(df)\n",
    "    mask_valid = (df[TARGET_COL] >= 0.0) & (df[TARGET_COL] <= 1.0)\n",
    "    df = df.loc[mask_valid].copy()\n",
    "    dropped_out_of_range = before_range - len(df)\n",
    "\n",
    "    # Normalize string columns\n",
    "    for c in ['kepoi_name', 'kepler_name', 'koi_disposition', 'koi_pdisposition']:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype('string').str.strip()\n",
    "\n",
    "    # Save clean CSV\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    df.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f'Loaded rows: {orig_rows}')\n",
    "    print(f'Dropped exact duplicates: {dropped_dupes}')\n",
    "    print(f'Dropped missing koi_score: {dropped_y_na}')\n",
    "    print(f'Dropped out-of-range koi_score: {dropped_out_of_range}')\n",
    "    print(f'Kept columns ({len(keep_cols)}): {keep_cols}')\n",
    "    print(f'Final shape: {df.shape}')\n",
    "    print(f'Saved to: {out_path}')\n",
    "    return df\n",
    "\n",
    "# Run cleaning once to produce data/koi_clean.csv\n",
    "FORCE_REBUILD = False  # set True to overwrite existing clean file if needed\n",
    "if FORCE_REBUILD or (not os.path.exists(CLEAN_PATH)):\n",
    "    _df_clean = clean_koi(RAW_PATH, CLEAN_PATH)\n",
    "else:\n",
    "    print(f'Clean file already exists at {CLEAN_PATH}. Set FORCE_REBUILD=True and re-run this cell to rebuild.')"
   ],
   "id": "925898fff35009f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Cleaned Data (use this for EDA/PCA/Models)\n",
    "This block loads only the clean dataset. Use it for all downstream analysis."
   ],
   "id": "6e32eff7cfa6ee48"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "load-data"
    ]
   },
   "source": [
    "# Load the cleaned dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "CLEAN_CANDIDATES = [\n",
    "    os.path.join('data', 'koi_clean.csv'),\n",
    "    os.path.join('..', 'data', 'koi_clean.csv'),\n",
    "]\n",
    "CLEAN_PATH = next((p for p in CLEAN_CANDIDATES if os.path.isfile(p)), CLEAN_CANDIDATES[0])\n",
    "df = pd.read_csv(CLEAN_PATH, low_memory=False)\n",
    "\n",
    "# Re-declare column groups for standalone use of this cell onward\n",
    "IDENTIFIER_COLS = ['kepid', 'kepoi_name', 'kepler_name']\n",
    "TARGET_COL = 'koi_score'\n",
    "LABEL_COLS = ['koi_disposition','koi_pdisposition','koi_fpflag_nt','koi_fpflag_ss','koi_fpflag_co','koi_fpflag_ec']\n",
    "FEATURE_COLS = [\n",
    "    'koi_period','koi_time0bk','koi_impact','koi_duration','koi_depth','koi_model_snr',\n",
    "    'koi_prad','koi_teq','koi_insol','koi_steff','koi_slogg','koi_srad','ra','dec','koi_kepmag'\n",
    "]\n",
    "\n",
    "print(f'Loaded clean dataset: {df.shape[0]} rows x {df.shape[1]} columns')\n",
    "df.head()"
   ],
   "id": "877b711a459c9da9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of koi_score\n",
    "Basic distribution of the target to assess skew and mass near 0/1."
   ],
   "id": "6425f48747d0ef5b"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "eda",
     "koi_score-distribution"
    ]
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "ax = sns.histplot(df['koi_score'].dropna(), bins=40, kde=True, color='#1f77b4', edgecolor='white')\n",
    "ax.set_title('Distribution of koi_score')\n",
    "ax.set_xlabel('koi_score')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('koi_score summary:')\n",
    "print(df['koi_score'].describe().to_string())\n"
   ],
   "id": "30e9fecbab835bb7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
