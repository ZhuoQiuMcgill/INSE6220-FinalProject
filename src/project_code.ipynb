{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# INSE6220 Final Project — KOI koi_score Surrogate Model\n",
    "\n",
    "This notebook follows the agreed framework: clean the raw KOI table, save a clean dataset for reuse, and provide a dedicated \"Load Cleaned Data\" block for all later steps (EDA, PCA, and modeling)."
   ],
   "id": "56a90c54dc1f61f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## How to use this notebook\n",
    "1. Run the Setup cells below.\n",
    "2. Run the \"Data Cleaning (run once)\" cell to generate `data/koi_clean.csv`.\n",
    "3. For all later work, use the \"Load Cleaned Data\" cell only — do not re-run cleaning (to avoid leakage and ensure reproducibility)."
   ],
   "id": "12f0306a23db7d21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup: imports and paths\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Resolve raw and clean paths robustly relative to working directory\n",
    "RAW_CANDIDATES = [\n",
    "    os.path.join('data', 'koi.csv'),\n",
    "    os.path.join('..', 'data', 'koi.csv'),\n",
    "]\n",
    "RAW_PATH = next((p for p in RAW_CANDIDATES if os.path.isfile(p)), RAW_CANDIDATES[0])\n",
    "DATA_DIR = os.path.dirname(RAW_PATH) if os.path.basename(RAW_PATH) else os.path.join('data')\n",
    "CLEAN_PATH = os.path.join(DATA_DIR, 'koi_clean.csv')"
   ],
   "id": "c342242dcae87be4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Column groups (kept consistent with the framework)\n",
    "IDENTIFIER_COLS = [\n",
    "    'kepid',            # Kepler Catalog ID\n",
    "    'kepoi_name',       # KOI Name\n",
    "    'kepler_name',      # Official Kepler Planet Name (if any)\n",
    "]\n",
    "\n",
    "TARGET_COL = 'koi_score'\n",
    "\n",
    "LABEL_COLS = [\n",
    "    'koi_disposition',     # Exoplanet Archive Disposition\n",
    "    'koi_pdisposition',    # Disposition Using Kepler Data\n",
    "    'koi_fpflag_nt',       # Not Transit-Like FP flag\n",
    "    'koi_fpflag_ss',       # Stellar Eclipse FP flag\n",
    "    'koi_fpflag_co',       # Centroid Offset FP flag\n",
    "    'koi_fpflag_ec',       # Ephemeris Match FP flag\n",
    "]\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    # Transit geometry & shape\n",
    "    'koi_period',\n",
    "    'koi_time0bk',\n",
    "    'koi_impact',\n",
    "    'koi_duration',\n",
    "    'koi_depth',\n",
    "    'koi_model_snr',\n",
    "    # Planet properties & irradiation\n",
    "    'koi_prad',\n",
    "    'koi_teq',\n",
    "    'koi_insol',\n",
    "    # Stellar properties\n",
    "    'koi_steff',\n",
    "    'koi_slogg',\n",
    "    'koi_srad',\n",
    "    # Sky position & brightness\n",
    "    'ra',\n",
    "    'dec',\n",
    "    'koi_kepmag',\n",
    "]\n",
    "\n",
    "# Always drop from feature matrix (metadata), per framework\n",
    "DROP_ALWAYS = ['koi_tce_plnt_num', 'koi_tce_delivname']\n",
    "\n",
    "ALL_KEEP_COLS = IDENTIFIER_COLS + [TARGET_COL] + LABEL_COLS + FEATURE_COLS"
   ],
   "id": "a939dd1feb017d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Cleaning (run once)\n",
    "Cleans the raw KOI table according to the framework and writes `data/koi_clean.csv`.\n",
    "\n",
    "Notes:\n",
    "- Skips comment lines from the raw NASA export.\n",
    "- Retains identifier columns, target `koi_score`, label/flag columns, and the primary feature columns (central values only).\n",
    "- Drops uncertainty columns (`*_err1`, `*_err2`) implicitly by not selecting them.\n",
    "- Drops exact duplicate rows.\n",
    "- Drops rows with missing or out-of-range `koi_score`.\n",
    "- Does not impute feature missing values here (to avoid leakage) — handle later within ML pipelines."
   ],
   "id": "f4be0ef26062b3f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clean_koi(raw_path: str, out_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load raw KOI CSV, select relevant columns, enforce basic validity of koi_score,\n",
    "    and save a clean CSV for downstream use.\n",
    "    \"\"\"\n",
    "    # Load raw CSV; ignore NASA header comments starting with '#'\n",
    "    df = pd.read_csv(raw_path, comment='#', low_memory=False)\n",
    "    orig_rows = len(df)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Keep only the specified columns if present\n",
    "    keep_cols = [c for c in ALL_KEEP_COLS if c in df.columns]\n",
    "    df = df.loc[:, keep_cols].copy()\n",
    "\n",
    "    # Drop exact duplicate rows\n",
    "    before_dupes = len(df)\n",
    "    df = df.drop_duplicates()\n",
    "    dropped_dupes = before_dupes - len(df)\n",
    "\n",
    "    # Coerce numeric columns\n",
    "    numeric_cols = set(FEATURE_COLS + [TARGET_COL, 'kepid'])\n",
    "    numeric_cols.update([c for c in LABEL_COLS if c.startswith('koi_fpflag_')])\n",
    "    numeric_cols = [c for c in numeric_cols if c in df.columns]\n",
    "    for c in numeric_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    # Remove rows with missing target\n",
    "    before_drop_y_na = len(df)\n",
    "    df = df.dropna(subset=[TARGET_COL])\n",
    "    dropped_y_na = before_drop_y_na - len(df)\n",
    "\n",
    "    # Enforce koi_score within [0, 1]\n",
    "    before_range = len(df)\n",
    "    mask_valid = (df[TARGET_COL] >= 0.0) & (df[TARGET_COL] <= 1.0)\n",
    "    df = df.loc[mask_valid].copy()\n",
    "    dropped_out_of_range = before_range - len(df)\n",
    "\n",
    "    # Normalize string columns\n",
    "    for c in ['kepoi_name', 'kepler_name', 'koi_disposition', 'koi_pdisposition']:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype('string').str.strip()\n",
    "\n",
    "    # Save clean CSV\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    df.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f'Loaded rows: {orig_rows}')\n",
    "    print(f'Dropped exact duplicates: {dropped_dupes}')\n",
    "    print(f'Dropped missing koi_score: {dropped_y_na}')\n",
    "    print(f'Dropped out-of-range koi_score: {dropped_out_of_range}')\n",
    "    print(f'Kept columns ({len(keep_cols)}): {keep_cols}')\n",
    "    print(f'Final shape: {df.shape}')\n",
    "    print(f'Saved to: {out_path}')\n",
    "    return df\n",
    "\n",
    "# Run cleaning once to produce data/koi_clean.csv\n",
    "FORCE_REBUILD = False  # set True to overwrite existing clean file if needed\n",
    "if FORCE_REBUILD or (not os.path.exists(CLEAN_PATH)):\n",
    "    _df_clean = clean_koi(RAW_PATH, CLEAN_PATH)\n",
    "else:\n",
    "    print(f'Clean file already exists at {CLEAN_PATH}. Set FORCE_REBUILD=True and re-run this cell to rebuild.')"
   ],
   "id": "590a81aacfa6e331",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load Cleaned Data (use this for EDA/PCA/Models)\n",
    "This block loads only the clean dataset. Use it for all downstream analysis."
   ],
   "id": "942ae16313f5bdca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the cleaned dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "CLEAN_CANDIDATES = [\n",
    "    os.path.join('data', 'koi_clean.csv'),\n",
    "    os.path.join('..', 'data', 'koi_clean.csv'),\n",
    "]\n",
    "CLEAN_PATH = next((p for p in CLEAN_CANDIDATES if os.path.isfile(p)), CLEAN_CANDIDATES[0])\n",
    "df = pd.read_csv(CLEAN_PATH, low_memory=False)\n",
    "\n",
    "# Re-declare column groups for standalone use of this cell onward\n",
    "IDENTIFIER_COLS = ['kepid', 'kepoi_name', 'kepler_name']\n",
    "TARGET_COL = 'koi_score'\n",
    "LABEL_COLS = ['koi_disposition','koi_pdisposition','koi_fpflag_nt','koi_fpflag_ss','koi_fpflag_co','koi_fpflag_ec']\n",
    "FEATURE_COLS = [\n",
    "    'koi_period','koi_time0bk','koi_impact','koi_duration','koi_depth','koi_model_snr',\n",
    "    'koi_prad','koi_teq','koi_insol','koi_steff','koi_slogg','koi_srad','ra','dec','koi_kepmag'\n",
    "]\n",
    "\n",
    "print(f'Loaded clean dataset: {df.shape[0]} rows x {df.shape[1]} columns')\n",
    "df.head()"
   ],
   "id": "877b711a459c9da9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box plots with automatic log transform (recommended)\n",
    "Decides per-column whether to apply a log10 transform (based on skewness and dynamic range), prints the decision, and plots box plots accordingly."
   ],
   "id": "a89ed3b4999b4b30"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "eda",
     "boxplots-log"
    ]
   },
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Candidate numeric columns\n",
    "all_numeric = [c for c in df.select_dtypes(include=['number']).columns]\n",
    "# Exclude id/target and fp flags (treated as discrete)\n",
    "exclude_base = {'kepid','koi_score'}\n",
    "exclude_base.update([c for c in df.columns if c.startswith('koi_fpflag_')])\n",
    "# Identify discrete small-cardinality numeric columns to skip in box plots\n",
    "discrete_small = [c for c in all_numeric if df[c].nunique(dropna=True) <= 5]\n",
    "numeric_cols = [c for c in all_numeric if c not in exclude_base and c not in discrete_small]\n",
    "\n",
    "# Columns we keep linear due to physical meaning (angles/magnitude)\n",
    "never_log = {'ra','dec','koi_kepmag'}\n",
    "\n",
    "log10_cols, log1p_cols, linear_cols = [], [], []\n",
    "for col in numeric_cols:\n",
    "    s = pd.to_numeric(df[col], errors='coerce').dropna()\n",
    "    if col in never_log:\n",
    "        linear_cols.append(col)\n",
    "        continue\n",
    "    if len(s) < 3:\n",
    "        linear_cols.append(col)\n",
    "        continue\n",
    "    skew = float(s.skew())\n",
    "    q95, q05 = s.quantile(0.95), s.quantile(0.05)\n",
    "    ratio = (q95 / max(q05, 1e-12)) if q05 > 0 else np.inf\n",
    "    criterion = (skew > 0.75) or (ratio > 20)\n",
    "    minv = float(s.min())\n",
    "    if criterion and minv > 0:\n",
    "        log10_cols.append(col)\n",
    "    elif criterion and minv >= 0:\n",
    "        log1p_cols.append(col)\n",
    "    else:\n",
    "        linear_cols.append(col)\n",
    "\n",
    "# Create transformed copy for plotting\n",
    "plot_df = df.copy()\n",
    "for col in log10_cols:\n",
    "    plot_df[col] = np.log10(plot_df[col])\n",
    "for col in log1p_cols:\n",
    "    plot_df[col] = np.log10(plot_df[col] + 1.0)\n",
    "\n",
    "print('Skipped discrete/binary columns:', discrete_small)\n",
    "print('Log10 columns:', log10_cols)\n",
    "print('Log10(1+x) columns:', log1p_cols)\n",
    "print('Linear columns:', linear_cols)\n",
    "\n",
    "# Plot box plots using transformed data where applicable\n",
    "cols_to_plot = numeric_cols\n",
    "ncols = 4\n",
    "nrows = math.ceil(len(cols_to_plot) / ncols)\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(4.8 * ncols, 3.0 * nrows), squeeze=False)\n",
    "\n",
    "for i, col in enumerate(cols_to_plot):\n",
    "    r, c = divmod(i, ncols)\n",
    "    ax = axes[r][c]\n",
    "    sns.boxplot(x=plot_df[col].dropna(), ax=ax, color='#9467bd', orient='h', whis=1.5, showfliers=False)\n",
    "    tr = ' (log10)' if col in log10_cols else (' (log10(1+x))' if col in log1p_cols else '')\n",
    "    ax.set_title(col + tr)\n",
    "    ax.grid(True, axis='x', linestyle=':', alpha=0.35)\n",
    "\n",
    "# Hide unused axes\n",
    "total_axes = nrows * ncols\n",
    "for j in range(len(cols_to_plot), total_axes):\n",
    "    r, c = divmod(j, ncols)\n",
    "    axes[r][c].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "67789d37dbe0bd19",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute–koi_score correlation and covariance\n",
    "Absolute Pearson correlation and covariance with koi_score for model-relevant features (excludes ID and flags)."
   ],
   "id": "b5be406e05ff8367"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "eda",
     "corr-cov"
    ]
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Use model-relevant numeric features only to avoid label leakage\n",
    "features = [c for c in FEATURE_COLS if c in df.columns]\n",
    "\n",
    "y = pd.to_numeric(df[TARGET_COL], errors='coerce')\n",
    "rows = []\n",
    "for col in features:\n",
    "    x = pd.to_numeric(df[col], errors='coerce')\n",
    "    m = x.notna() & y.notna()\n",
    "    if m.sum() < 3:\n",
    "        corr = np.nan\n",
    "        cov = np.nan\n",
    "    else:\n",
    "        corr = x[m].corr(y[m])\n",
    "        cov = x[m].cov(y[m])\n",
    "    rows.append({\n",
    "        'feature': col,\n",
    "        'corr': corr,\n",
    "        'abs_corr': np.abs(corr) if pd.notna(corr) else np.nan,\n",
    "        'cov': cov,\n",
    "        'abs_cov': np.abs(cov) if pd.notna(cov) else np.nan\n",
    "    })\n",
    "\n",
    "stats = pd.DataFrame(rows).dropna(subset=['abs_corr'])\n",
    "stats_corr = stats.sort_values('abs_corr', ascending=False)\n",
    "stats_cov = stats.dropna(subset=['abs_cov']).sort_values('abs_cov', ascending=False)\n",
    "\n",
    "# Plot absolute correlation and covariance\n",
    "N = min(20, len(stats_corr)) if len(stats_corr) else 0\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, max(4, 0.35 * max(N, 8))), sharex=False)\n",
    "\n",
    "if N > 0:\n",
    "    sub = stats_corr.head(N)\n",
    "    sns.barplot(ax=axes[0], y='feature', x='abs_corr', data=sub, color='#1f77b4')\n",
    "    axes[0].set_title('Abs Pearson correlation with koi_score (top {})'.format(N))\n",
    "    axes[0].set_xlabel('|corr|')\n",
    "    axes[0].set_ylabel('feature')\n",
    "else:\n",
    "    axes[0].set_visible(False)\n",
    "\n",
    "M = min(20, len(stats_cov)) if len(stats_cov) else 0\n",
    "if M > 0:\n",
    "    sub2 = stats_cov.head(M)\n",
    "    sns.barplot(ax=axes[1], y='feature', x='abs_cov', data=sub2, color='#ff7f0e')\n",
    "    axes[1].set_title('Abs covariance with koi_score (top {})'.format(M))\n",
    "    axes[1].set_xlabel('|cov|')\n",
    "    axes[1].set_ylabel('feature')\n",
    "else:\n",
    "    axes[1].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Top 10 by |corr|:')\n",
    "print(stats_corr[['feature','corr']].head(10).to_string(index=False))\n",
    "print()\n",
    "print('Top 10 by |cov|:')\n",
    "print(stats_cov[['feature','cov']].head(10).to_string(index=False))\n"
   ],
   "id": "b2854c85609cbddf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of koi_score\n",
    "Basic distribution of the target to assess skew and mass near 0/1."
   ],
   "id": "6425f48747d0ef5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "ax = sns.histplot(df['koi_score'].dropna(), bins=40, kde=True, color='#1f77b4', edgecolor='white')\n",
    "ax.set_title('Distribution of koi_score')\n",
    "ax.set_xlabel('koi_score')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('koi_score summary:')\n",
    "print(df['koi_score'].describe().to_string())\n"
   ],
   "id": "d26c40a224e5dda0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
